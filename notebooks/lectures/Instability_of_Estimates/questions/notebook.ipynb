{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises: Instability of Parameter Estimates\n",
    "\n",
    "## Lecture Link\n",
    "\n",
    "This exercise notebook refers to this lecture. Please use the lecture for explanations and sample code.\n",
    "\n",
    "https://www.quantopian.com/lectures#Instability-of-Estimates\n",
    "\n",
    "Part of the Quantopian Lecture Series:\n",
    "\n",
    "* [www.quantopian.com/lectures](https://www.quantopian.com/lectures)\n",
    "* [github.com/quantopian/research_public](https://github.com/quantopian/research_public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "TODAY = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def get_pricing(ticker, field='all', start_date='2008-01-01', end_date=TODAY):     \n",
    "    params = { \n",
    "        'access_key': 'pk_7cee023fd7874b4b893b2194cc61a972',\n",
    "        'symbols': ticker,\n",
    "        'date_from': start_date,\n",
    "        'date_to': end_date,\n",
    "        'limit': 1000\n",
    "    }\n",
    "    \n",
    "    request = requests.get('https://cloud.iexapis.com/', params)\n",
    "\n",
    "\n",
    "    try:\n",
    "        response = request.json()\n",
    "        data = response['data']\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df.set_index('date', inplace=True)\n",
    "            \n",
    "        if field == 'all':        \n",
    "            return df\n",
    "        \n",
    "        return df[field]\n",
    "        \n",
    "    except:\n",
    "        print(response['error'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "import quandl as ql\n",
    "import marketstack as ms\n",
    "from datetime import date\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "# import os\n",
    "# os.environ['IEX_TOKEN'] = 'pk_7cee023fd7874b4b893b2194cc61a972'\n",
    "\n",
    "# import sys  \n",
    "# sys.path.insert(0, '/Users/scottc/Documents/Personal/research_public/notebooks/utils')\n",
    "# print(sys.path)\n",
    "\n",
    "# Set a seed so we can play with the data without generating new random numbers every time\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Sample Size vs. Standard Deviation\n",
    "\n",
    "Using the below normal distribution with mean 100 and standard deviation 50, find the means and standard deviations of  samples of size 5, 25, 100, and 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size of 5\n",
      "mean: 84.90780397851248\n",
      "standard deviation: 54.13660413796328\n",
      "sample size of 25\n",
      "mean: 88.54023112211536\n",
      "standard deviation: 41.094283664341596\n",
      "sample size of 100\n",
      "mean: 94.69551491647579\n",
      "standard deviation: 48.633464591377084\n",
      "sample size of 500\n",
      "mean: 97.52503316239564\n",
      "standard deviation: 49.84308115486865\n",
      "As sample size increases, the mean and standard deviation approach those of the population. However, even at the 500 sample level the sample mean is not the same as the population mean.\n"
     ]
    }
   ],
   "source": [
    "POPULATION_MU = 100\n",
    "POPULATION_SIGMA = 25\n",
    "sample_sizes = [5, 25, 100, 500]\n",
    "\n",
    "#Your code goes here\n",
    "dist = np.random.normal(100, 50, 500)\n",
    "\n",
    "print('sample size of 5')\n",
    "print('mean:', np.mean(dist[:5]))\n",
    "print('standard deviation:', np.std(dist[:5]))\n",
    "\n",
    "print('sample size of 25')\n",
    "print('mean:', np.mean(dist[:25]))\n",
    "print('standard deviation:', np.std(dist[:25]))\n",
    "\n",
    "print('sample size of 100')\n",
    "print('mean:', np.mean(dist[:100]))\n",
    "print('standard deviation:', np.std(dist[:100]))\n",
    "\n",
    "print('sample size of 500')\n",
    "print('mean:', np.mean(dist[:500]))\n",
    "print('standard deviation:', np.std(dist[:500]))\n",
    "\n",
    "print('As sample size increases, the mean and standard deviation approach those of the population. However, even at the 500 sample level the sample mean is not the same as the population mean.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Instability of Predictions on Mean Alone\n",
    "\n",
    "## a. Finding Means\n",
    "\n",
    "Find the means of the following three data sets $X$, $Y$, and $Z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 25.0\n",
      "mean 24.686274509803923\n",
      "mean 25.607843137254903\n"
     ]
    }
   ],
   "source": [
    "X = [ 31.,   6.,  21.,  32.,  41.,   4.,  48.,  38.,  43.,  36.,  50., 20.,  46.,  33.,   8.,  27.,  17.,  44.,  16.,  39.,   3.,  37.,\n",
    "        35.,  13.,  49.,   2.,  18.,  42.,  22.,  25.,  15.,  24.,  11., 19.,   5.,  40.,  12.,  10.,   1.,  45.,  26.,  29.,   7.,  30.,\n",
    "        14.,  23.,  28.,   0.,  34.,   9.,  47.]\n",
    "Y = [ 15.,  41.,  33.,  29.,   3.,  28.,  28.,   8.,  15.,  22.,  39., 38.,  22.,  10.,  39.,  40.,  24.,  15.,  21.,  25.,  17.,  33.,\n",
    "        40.,  32.,  42.,   5.,  39.,   8.,  15.,  25.,  37.,  33.,  14., 25.,   1.,  31.,  45.,   5.,   6.,  19.,  13.,  39.,  18.,  49.,\n",
    "        13.,  38.,   8.,  25.,  32.,  40.,  17.]\n",
    "Z = [ 38.,  23.,  16.,  35.,  48.,  18.,  48.,  38.,  24.,  27.,  24., 35.,  37.,  28.,  11.,  12.,  31.,  -1.,   9.,  19.,  20.,   0.,\n",
    "        23.,  33.,  34.,  24.,  14.,  28.,  12.,  25.,  53.,  19.,  42., 21.,  15.,  36.,  47.,  20.,  26.,  41.,  33.,  50.,  26.,  22.,\n",
    "        -1.,  35.,  10.,  25.,  23.,  24.,   6.]\n",
    "\n",
    "#Your code goes here\n",
    "for a in [X, Y, Z]:\n",
    "    print('mean', np.mean(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Checking for Normality\n",
    "\n",
    "Use the `jarque_bera` function to conduct a Jarque-Bera test on $X$, $Y$, and $Z$ to determine whether their distributions are normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution is likely not normal\n",
      "p-value =  0.21602637949153217\n",
      "\n",
      "Distribution is likely not normal\n",
      "p-value =  0.25028131217047933\n",
      "\n",
      "Distribution is likely not normal\n",
      "p-value =  0.8669070017626075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Your code goes here\n",
    "for a in [X, Y, Z]:\n",
    "    _, p_value, _, _ = jarque_bera(a)\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print('Distribution is likely normal')\n",
    "        print('p-value = ', p_value)\n",
    "        print('')\n",
    "    else:\n",
    "        print('Distribution is likely not normal')\n",
    "        print('p-value = ', p_value)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Instability of Estimates\n",
    "\n",
    "Create a histogram of the sample distributions of $X$, $Y$, and $Z$ along with the best estimate/mean based on the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All three datasets have a similar mean, but have very different distributions. Mean alone is very non-informative about what is going on in data, and should not be used alone as an estimator.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Your code goes here\n",
    "plt.hist([X, Y, Z], stacked=True, alpha = 0.7)\n",
    "\n",
    "plt.axvline(np.mean(X));\n",
    "plt.axvline(np.mean(Y), c='r');\n",
    "plt.axvline(np.mean(Z), c='g');\n",
    "\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Value');\n",
    "\n",
    "print('All three datasets have a similar mean, but have very different distributions. Mean alone is very non-informative about what is going on in data, and should not be used alone as an estimator.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Sharpe Ratio Window Adjustment\n",
    "\n",
    "## a. Effect on Variability\n",
    "\n",
    "Just as in the lecture, find the mean and standard deviation of the running sharpe ratio for THO, this time testing for multiple window lengths: 300, 150, and 50. Restrict your mean and standard deviation calculation to pricing data up to 200 days away from the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Mean  50: -0.063775        Std  50: 0.10852786550185405\n",
      "Sharpe Mean 150: -0.051049        Std 150: 0.04837802621082556\n",
      "Sharpe Mean 300: -0.042091        Std 300: 0.03228526010407838\n",
      "As we increase the length of the window, the variability of the running sharpe ratio decreases.\n"
     ]
    }
   ],
   "source": [
    "def sharpe_ratio(asset, riskfree):\n",
    "    return np.mean(asset - riskfree)/np.std(asset - riskfree)\n",
    "\n",
    "import quandl as ql\n",
    "\n",
    "import pyEX as p\n",
    "import pandas_datareader.data as web\n",
    "from datetime import date\n",
    "\n",
    "start = datetime.datetime(2010, 1, 1)\n",
    "end = datetime.datetime(2015, 1, 1)\n",
    "# end = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "THO = web.DataReader('THO', 'iex', start=start, end=end, api_key=os.getenv('IEX_API_KEY'))\n",
    "THO.index = pd.to_datetime(THO.index)\n",
    "THO = THO['close'].pct_change()[1:]\n",
    "\n",
    "TBILL_3_Month = ql.get('USTREASURY/BILLRATES', start_date=start, end_date=end)\n",
    "TBILL_3_Month = TBILL_3_Month['13 Wk Bank Discount Rate'].pct_change()[1:]\n",
    "\n",
    "for window in [50, 150, 300]:\n",
    "    running_sharpe = [sharpe_ratio(THO[i-window+10:i], TBILL_3_Month[i-window+10:i]) for i in range(window-10, len(THO))]\n",
    "    running_sharpe = [x for x in running_sharpe if str(x) != 'nan']\n",
    "\n",
    "    mean_rs = np.mean(running_sharpe[:-200])\n",
    "    std_rs = np.std(running_sharpe[:-200])\n",
    "    \n",
    "    row = 'Sharpe Mean',(window),':', mean_rs,'Std', window,':',std_rs\n",
    "    print('{} {:>3}{} {:<11f}    {:>5} {:>3}{} {}'.format(*row))\n",
    "    \n",
    "print('As we increase the length of the window, the variability of the running sharpe ratio decreases.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Out-of-Sample Instability\n",
    "\n",
    "Plot the running sharpe ratio of all three window lengths, as well as their in-sample mean and standard deviation bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         0  DTB3\n",
      "date                            \n",
      "2019-03-18           63.87   NaN\n",
      "2019-03-19           62.96   NaN\n",
      "2019-03-20           60.34   NaN\n",
      "2019-03-21           61.49   NaN\n",
      "2019-03-22           57.86   NaN\n",
      "...                    ...   ...\n",
      "2021-03-10 00:00:00    NaN  0.04\n",
      "2021-03-11 00:00:00    NaN  0.04\n",
      "2021-03-12 00:00:00    NaN  0.04\n",
      "2021-03-15 00:00:00    NaN  0.04\n",
      "2021-03-16 00:00:00    NaN  0.02\n",
      "\n",
      "[1026 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Weather\n",
    "\n",
    "## a. Temperature in Boston\n",
    "\n",
    "Find the mean and standard deviation of Boston weekly average temperature data for the year of 2015 stored in `b15_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekly Avg Temp    49.076923\n",
      "dtype: float64\n",
      "Weekly Avg Temp    22.983979\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "b15_df = pd.DataFrame([ 29.,  22.,  19.,  17.,  19.,  19.,  15.,  16.,  18.,  25.,  21.,\n",
    "        25.,  29.,  27.,  36.,  38.,  40.,  44.,  49.,  50.,  58.,  61.,\n",
    "        67.,  69.,  74.,  72.,  76.,  81.,  81.,  80.,  83.,  82.,  80.,\n",
    "        79.,  79.,  80.,  74.,  72.,  68.,  68.,  65.,  61.,  57.,  50.,\n",
    "        46.,  42.,  41.,  35.,  30.,  27.,  28.,  28.],\n",
    "        columns = ['Weekly Avg Temp'],\n",
    "        index = pd.date_range('1/1/2012', periods=52, freq='W')          )\n",
    "\n",
    "#Your code goes here\n",
    "mean_b15_df = np.mean(b15_df)\n",
    "std_b15_df = np.std(b15_df)\n",
    "\n",
    "print(mean_b15_df)\n",
    "print(std_b15_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Temperature in Palo Alto\n",
    "\n",
    "Find the mean and standard deviation of Palo Alto weekly average temperature data for the year of 2015 stored in `p15_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekly Avg Temp    59.788462\n",
      "dtype: float64\n",
      "Weekly Avg Temp    7.974325\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "p15_df = pd.DataFrame([ 49.,  53.,  51.,  47.,  50.,  46.,  49.,  51.,  49.,  45.,  52.,\n",
    "        54.,  54.,  55.,  55.,  57.,  56.,  56.,  57.,  63.,  63.,  65.,\n",
    "        65.,  69.,  67.,  70.,  67.,  67.,  68.,  68.,  70.,  72.,  72.,\n",
    "        70.,  72.,  70.,  66.,  66.,  68.,  68.,  65.,  66.,  62.,  61.,\n",
    "        63.,  57.,  55.,  55.,  55.,  55.,  55.,  48.],\n",
    "        columns = ['Weekly Avg Temp'],\n",
    "        index = pd.date_range('1/1/2012', periods=52, freq='W'))\n",
    "\n",
    "#Your code goes here\n",
    "mean_p15_df = np.mean(p15_df)\n",
    "std_p15_df = np.std(p15_df)\n",
    "\n",
    "print(mean_p15_df)\n",
    "print(std_p15_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Predicting 2016 Temperatures\n",
    "\n",
    "Use the means you found in parts a and b to attempt to predict  2016 temperature data for both cities. Do this by creating two histograms for the 2016 temperature data in `b16_df` and `p16_df` with a vertical line where the 2015 means were to represent your prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b16_df = pd.DataFrame([ 26.,  22.,  20.,  19.,  18.,  19.,  17.,  17.,  19.,  20.,  23., 22.,  28.,  28.,  35.,  38.,  42.,  47.,  49.,  56.,  59.,  61.,\n",
    "        61.,  70.,  73.,  73.,  73.,  77.,  78.,  82.,  80.,  80.,  81., 78.,  82.,  78.,  76.,  71.,  69.,  66.,  60.,  63.,  56.,  50.,\n",
    "        44.,  43.,  34.,  33.,  31.,  28.,  27.,  20.],\n",
    "        columns = ['Weekly Avg Temp'],\n",
    "        index = pd.date_range('1/1/2012', periods=52, freq='W'))\n",
    "\n",
    "p16_df = pd.DataFrame([ 50.,  50.,  51.,  48.,  48.,  49.,  50.,  45.,  52.,  50.,  51., 52.,  50.,  56.,  58.,  55.,  61.,  56.,  61.,  62.,  62.,  64.,\n",
    "        64.,  69.,  71.,  66.,  69.,  70.,  68.,  71.,  70.,  69.,  72., 71.,  66.,  69.,  70.,  70.,  66.,  67.,  64.,  64.,  65.,  61.,\n",
    "        61.,  59.,  56.,  53.,  55.,  52.,  52.,  51.],\n",
    "        columns = ['Weekly Avg Temp'],\n",
    "        index = pd.date_range('1/1/2012', periods=52, freq='W'))\n",
    "\n",
    "#Your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Congratulations on completing the instability of parameter estimates exercises!\n",
    "\n",
    "As you learn more about writing trading models and the Quantopian platform, enter a daily [Quantopian Contest](https://www.quantopian.com/contest). Your strategy will be evaluated for a cash prize every day.\n",
    "\n",
    "Start by going through the [Writing a Contest Algorithm](https://www.quantopian.com/tutorials/contest) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date*This presentation is for informational purposes only and does not constitute an offer to sell, a solic\n",
    "itation to buy, or a recommendation for any security; nor does it constitute an offer to provide investment advisory or other services by Quantopian, Inc. (\"Quantopian\"). Nothing contained herein constitutes investment advice or offers any opinion with respect to the suitability of any security, and any views expressed herein should not be taken as advice to buy, sell, or hold any security or as an endorsement of any security or company.  In preparing the information contained herein, Quantopian, Inc. has not taken into account the investment needs, objectives, and financial circumstances of any particular investor. Any views expressed and data illustrated herein were prepared based upon information, believed to be reliable, available to Quantopian, Inc. at the time of publication. Quantopian makes no guarantees as to their accuracy or completeness. All information is subject to change and may quickly become unreliable for various reasons, including changes in market conditions or economic circumstances.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
